{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN,LSTM,Dense,Activation,Input,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_emoji.csv',header = None)\n",
    "test_data = pd.read_csv('./test_emoji.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132, 5)\n",
      "(56,) (56,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.values\n",
    "y_train = x_train[:,1]\n",
    "x_train = x_train[:,0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "x_test = test_data.values\n",
    "y_test = x_test[:,1]\n",
    "x_test = x_test[:,0]\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§\n",
      "1 ‚öæ\n",
      "2 üòÑ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2 : \":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}\n",
    "for ix in emoji_dict.keys():\n",
    "    print(ix,emoji.emojize(emoji_dict[ix],use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(x_train.shape[0]):\n",
    "    x_train[ix] = x_train[ix].split()\n",
    "    \n",
    "for ix in range(x_test.shape[0]):\n",
    "    x_test[ix] = x_test[ix].split()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9a70521400ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./glove.6B.50d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "f = open('./glove.6B.50d.txt')\n",
    "\n",
    "for line in f:\n",
    "    data = line.split()\n",
    "    word = data[0]\n",
    "    coeff = np.asarray(data[1:], dtype='float32')\n",
    "    embedding_index[word] = coeff\n",
    "f.close()\n",
    "print(len(embedding_index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_index['india'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "max_length_train = np.sort(np.array([len(ix) for ix in x_train]))[-1]\n",
    "print(max_length_train)\n",
    "\n",
    "embedding_matrix_train = np.zeros((x_train.shape[0], max_length_train, 50))\n",
    "embedding_matrix_test = np.zeros((x_test.shape[0], max_length_train, 50))\n",
    "\n",
    "for ix in range(x_train.shape[0]):\n",
    "    for ij in range(len(x_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embedding_index[x_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(x_test.shape[0]):\n",
    "    for ij in range(len(x_test[ix])):\n",
    "        embedding_matrix_test[ix][ij] = embedding_index[x_test[ix][ij].lower()]  \n",
    "print(embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 15,941\n",
      "Trainable params: 15,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.9061 - acc: 0.2500\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 431us/step - loss: 1.7329 - acc: 0.2348\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 573us/step - loss: 1.7183 - acc: 0.3182\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 516us/step - loss: 1.6786 - acc: 0.3333\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 390us/step - loss: 1.5560 - acc: 0.3864\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 494us/step - loss: 1.5342 - acc: 0.3030\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 584us/step - loss: 1.5012 - acc: 0.3485\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 721us/step - loss: 1.3670 - acc: 0.4697\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 621us/step - loss: 1.4038 - acc: 0.4394\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 605us/step - loss: 1.1998 - acc: 0.5379\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 727us/step - loss: 1.1784 - acc: 0.5379\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 707us/step - loss: 1.0504 - acc: 0.5833\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 698us/step - loss: 1.0631 - acc: 0.5606\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 593us/step - loss: 1.1298 - acc: 0.5758\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 553us/step - loss: 1.0667 - acc: 0.5758\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 663us/step - loss: 1.0087 - acc: 0.6061\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 508us/step - loss: 0.9068 - acc: 0.6439\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 558us/step - loss: 0.9030 - acc: 0.6667\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 611us/step - loss: 0.8556 - acc: 0.7348\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 669us/step - loss: 0.7970 - acc: 0.6894\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 594us/step - loss: 0.7739 - acc: 0.7121\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 690us/step - loss: 0.7546 - acc: 0.6970\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 658us/step - loss: 0.7327 - acc: 0.6970\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 686us/step - loss: 0.6743 - acc: 0.7803\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 650us/step - loss: 0.5745 - acc: 0.8258\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 655us/step - loss: 0.5819 - acc: 0.7955\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 652us/step - loss: 0.5121 - acc: 0.8258\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 533us/step - loss: 0.5125 - acc: 0.8409\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 632us/step - loss: 0.5293 - acc: 0.7955\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 576us/step - loss: 0.4500 - acc: 0.8182\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 555us/step - loss: 0.4595 - acc: 0.8561\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 572us/step - loss: 0.4267 - acc: 0.8636\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 597us/step - loss: 0.3789 - acc: 0.8561\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 433us/step - loss: 0.3405 - acc: 0.8636\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 857us/step - loss: 0.3071 - acc: 0.9318\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 917us/step - loss: 0.3846 - acc: 0.8636\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 543us/step - loss: 0.2936 - acc: 0.8864\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 498us/step - loss: 0.2335 - acc: 0.9470\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 465us/step - loss: 0.2410 - acc: 0.9470\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 619us/step - loss: 0.2411 - acc: 0.9242\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 671us/step - loss: 0.2658 - acc: 0.8939\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 598us/step - loss: 0.2407 - acc: 0.9318\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 612us/step - loss: 0.2186 - acc: 0.9545\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 616us/step - loss: 0.1911 - acc: 0.9545\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 575us/step - loss: 0.1548 - acc: 0.9697\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 563us/step - loss: 0.1698 - acc: 0.9697\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 611us/step - loss: 0.1580 - acc: 0.9773\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 603us/step - loss: 0.1467 - acc: 0.9848\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 569us/step - loss: 0.1591 - acc: 0.9545\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 835us/step - loss: 0.1515 - acc: 0.9697\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 895us/step - loss: 0.1185 - acc: 0.9848\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 977us/step - loss: 0.1896 - acc: 0.9697\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 788us/step - loss: 0.1283 - acc: 0.9621\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 966us/step - loss: 0.1532 - acc: 0.9621\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 916us/step - loss: 0.1465 - acc: 0.9621\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 998us/step - loss: 0.1109 - acc: 0.9848\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 576us/step - loss: 0.1222 - acc: 0.9773\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 381us/step - loss: 0.1509 - acc: 0.9697\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 491us/step - loss: 0.1448 - acc: 0.9773\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 468us/step - loss: 0.0888 - acc: 0.9924\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 479us/step - loss: 0.1273 - acc: 0.9848\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 370us/step - loss: 0.0890 - acc: 0.9848\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 408us/step - loss: 0.0795 - acc: 0.9924\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 787us/step - loss: 0.0727 - acc: 0.9924\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 826us/step - loss: 0.0827 - acc: 0.9924\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 694us/step - loss: 0.0665 - acc: 0.9848\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 598us/step - loss: 0.0731 - acc: 0.9924\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 566us/step - loss: 0.0776 - acc: 0.9924\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 354us/step - loss: 0.0942 - acc: 0.9848\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 539us/step - loss: 0.1147 - acc: 0.9697\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 374us/step - loss: 0.0874 - acc: 0.9848\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 393us/step - loss: 0.0790 - acc: 0.9848\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 517us/step - loss: 0.0648 - acc: 0.9924\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 501us/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 635us/step - loss: 0.0673 - acc: 0.9848\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 515us/step - loss: 0.0703 - acc: 0.9924\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 503us/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 503us/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 465us/step - loss: 0.0540 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 442us/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 431us/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 443us/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 531us/step - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 609us/step - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 449us/step - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 382us/step - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 526us/step - loss: 0.0349 - acc: 0.9924\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 352us/step - loss: 0.0435 - acc: 0.9848\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 482us/step - loss: 0.0284 - acc: 0.9924\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 399us/step - loss: 0.0856 - acc: 0.9773\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 530us/step - loss: 0.0819 - acc: 0.9697\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 926us/step - loss: 0.0539 - acc: 0.9848\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 876us/step - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 935us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 793us/step - loss: 0.0464 - acc: 0.9924\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 782us/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 808us/step - loss: 0.0359 - acc: 0.9924\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 865us/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 960us/step - loss: 0.0295 - acc: 0.9924\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 514us/step - loss: 0.0237 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 100, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5178571428571429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "float(sum(pred==y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.6047 - acc: 0.2576\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.5297 - acc: 0.3182\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.4694 - acc: 0.3636\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.4343 - acc: 0.4318\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3137 - acc: 0.5227\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.2365 - acc: 0.4470\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.1501 - acc: 0.5379\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.9569 - acc: 0.6364\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.9427 - acc: 0.7273\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.7456 - acc: 0.7500\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6678 - acc: 0.7348\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5790 - acc: 0.8258\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5220 - acc: 0.8712\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5123 - acc: 0.8485\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5057 - acc: 0.7879\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4804 - acc: 0.8258\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4547 - acc: 0.8636\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3926 - acc: 0.8788\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3006 - acc: 0.9091\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2538 - acc: 0.9318\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9242\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2052 - acc: 0.9318\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2691 - acc: 0.9242\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1622 - acc: 0.9545\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1868 - acc: 0.9394\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2859 - acc: 0.9015\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1255 - acc: 0.9621\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1553 - acc: 0.9394\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1120 - acc: 0.9470\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1987 - acc: 0.9242\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1376 - acc: 0.9697\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5376 - acc: 0.8788\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4716 - acc: 0.8182\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2810 - acc: 0.8712\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2674 - acc: 0.8864\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1848 - acc: 0.9394\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2060 - acc: 0.9394\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1520 - acc: 0.9621\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1412 - acc: 0.9621\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9773\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0764 - acc: 0.9773\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0489 - acc: 0.9848\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0810 - acc: 0.9697\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0703 - acc: 0.9697\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0707 - acc: 0.9697\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0990 - acc: 0.9773\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0379 - acc: 0.9924\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0909 - acc: 0.9773\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1450 - acc: 0.9697\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0429 - acc: 0.9924\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0605 - acc: 0.9773\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0572 - acc: 0.9773\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.5919e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 100, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "float(sum(pred==y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 40,709\n",
      "Trainable params: 40,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 1.6077 - acc: 0.1970\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5396 - acc: 0.3030\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5107 - acc: 0.3561\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 971us/step - loss: 1.5247 - acc: 0.3333\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 812us/step - loss: 1.4934 - acc: 0.2955\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 889us/step - loss: 1.4444 - acc: 0.4470\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 806us/step - loss: 1.3448 - acc: 0.5152\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 822us/step - loss: 1.2824 - acc: 0.5076\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 825us/step - loss: 1.1940 - acc: 0.5682\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 804us/step - loss: 1.1643 - acc: 0.5682\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 846us/step - loss: 1.0713 - acc: 0.5758\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 836us/step - loss: 1.0352 - acc: 0.6364\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9671 - acc: 0.6136\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8740 - acc: 0.6742\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8582 - acc: 0.7197\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.7662 - acc: 0.7197\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 923us/step - loss: 0.7889 - acc: 0.7424\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 846us/step - loss: 0.7535 - acc: 0.7576\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 859us/step - loss: 0.7104 - acc: 0.7424\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 965us/step - loss: 0.5740 - acc: 0.8258\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 901us/step - loss: 0.6339 - acc: 0.7727\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 879us/step - loss: 0.5156 - acc: 0.8258\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 901us/step - loss: 0.5577 - acc: 0.7955\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 957us/step - loss: 0.4477 - acc: 0.8561\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 895us/step - loss: 0.4469 - acc: 0.8485\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 844us/step - loss: 0.3508 - acc: 0.8864\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4465 - acc: 0.8333\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 902us/step - loss: 0.3720 - acc: 0.8788\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 933us/step - loss: 0.3279 - acc: 0.8864\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 862us/step - loss: 0.4882 - acc: 0.8409\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 974us/step - loss: 0.3801 - acc: 0.8561\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 966us/step - loss: 0.2660 - acc: 0.9242\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 927us/step - loss: 0.2783 - acc: 0.9167\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 939us/step - loss: 0.2143 - acc: 0.9318\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 878us/step - loss: 0.2187 - acc: 0.9545\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 876us/step - loss: 0.1991 - acc: 0.9470\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 914us/step - loss: 0.2054 - acc: 0.9318\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 893us/step - loss: 0.1609 - acc: 0.9545\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 887us/step - loss: 0.1436 - acc: 0.9545\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1707 - acc: 0.9394\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 969us/step - loss: 0.1590 - acc: 0.9394\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 947us/step - loss: 0.1547 - acc: 0.9621\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 908us/step - loss: 0.0979 - acc: 0.9773\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 977us/step - loss: 0.0998 - acc: 0.9697\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 930us/step - loss: 0.0845 - acc: 0.9924\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 935us/step - loss: 0.0763 - acc: 0.9924\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 979us/step - loss: 0.0794 - acc: 0.9848\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 861us/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0540 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 867us/step - loss: 0.0638 - acc: 0.9848\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0410 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 858us/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 894us/step - loss: 0.0922 - acc: 0.9773\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 772us/step - loss: 0.0788 - acc: 0.9697\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 838us/step - loss: 0.0536 - acc: 0.9924\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 808us/step - loss: 0.0480 - acc: 0.9848\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 777us/step - loss: 0.0428 - acc: 0.9924\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 759us/step - loss: 0.0365 - acc: 0.9924\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 792us/step - loss: 0.0269 - acc: 0.9924\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 773us/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 815us/step - loss: 0.0660 - acc: 0.9773\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 833us/step - loss: 0.0632 - acc: 0.9773\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 845us/step - loss: 0.0630 - acc: 0.9773\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 797us/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 800us/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 773us/step - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0946 - acc: 0.9697\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 858us/step - loss: 0.1225 - acc: 0.9697\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 806us/step - loss: 0.0996 - acc: 0.9697\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 900us/step - loss: 0.0900 - acc: 0.9848\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2139 - acc: 0.9167\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 877us/step - loss: 0.0560 - acc: 0.9848\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 813us/step - loss: 0.0688 - acc: 0.9621\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 805us/step - loss: 0.1236 - acc: 0.9545\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 929us/step - loss: 0.1175 - acc: 0.9394\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 998us/step - loss: 0.1344 - acc: 0.9621\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 836us/step - loss: 0.1857 - acc: 0.9318\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 833us/step - loss: 0.0981 - acc: 0.9773\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 836us/step - loss: 0.0764 - acc: 0.9697\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 972us/step - loss: 0.0553 - acc: 0.9848\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0329 - acc: 0.9924\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 899us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 800us/step - loss: 0.0342 - acc: 0.9924\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 804us/step - loss: 0.0464 - acc: 0.9773\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 756us/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 913us/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.9924\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 987us/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 887us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 955us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 804us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 953us/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 900us/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 876us/step - loss: 0.0076 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 100, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "float(sum(pred==y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
