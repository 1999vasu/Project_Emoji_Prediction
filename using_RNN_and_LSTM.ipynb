{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN,LSTM,Dense,Activation,Input,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_emoji.csv',header = None)\n",
    "test_data = pd.read_csv('./test_emoji.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132, 5)\n",
      "(56,) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.values\n",
    "y_train = x_train[:,1]\n",
    "x_train = x_train[:,0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "x_test = test_data.values\n",
    "y_test = x_test[:,1]\n",
    "y_act = x_test[:,1]\n",
    "x_test = x_test[:,0]\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§\n",
      "1 ‚öæ\n",
      "2 üòÑ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2 : \":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}\n",
    "for ix in emoji_dict.keys():\n",
    "    print(ix,emoji.emojize(emoji_dict[ix],use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(x_train.shape[0]):\n",
    "    x_train[ix] = x_train[ix].split()\n",
    "    \n",
    "for ix in range(x_test.shape[0]):\n",
    "    x_test[ix] = x_test[ix].split()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "f = open('./glove.6B.50d.txt')\n",
    "\n",
    "for line in f:\n",
    "    data = line.split()\n",
    "    word = data[0]\n",
    "    coeff = np.asarray(data[1:], dtype='float32')\n",
    "    embedding_index[word] = coeff\n",
    "f.close()\n",
    "print(len(embedding_index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_index['india'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "max_length_train = np.sort(np.array([len(ix) for ix in x_train]))[-1]\n",
    "print(max_length_train)\n",
    "\n",
    "embedding_matrix_train = np.zeros((x_train.shape[0], max_length_train, 50))\n",
    "embedding_matrix_test = np.zeros((x_test.shape[0], max_length_train, 50))\n",
    "\n",
    "for ix in range(x_train.shape[0]):\n",
    "    for ij in range(len(x_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embedding_index[x_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(x_test.shape[0]):\n",
    "    for ij in range(len(x_test[ix])):\n",
    "        embedding_matrix_test[ix][ij] = embedding_index[x_test[ix][ij].lower()]  \n",
    "print(embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 15,941\n",
      "Trainable params: 15,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132 samples, validate on 56 samples\n",
      "Epoch 1/60\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.9594 - acc: 0.2273 - val_loss: 1.4924 - val_acc: 0.3571\n",
      "Epoch 2/60\n",
      "132/132 [==============================] - 0s 194us/step - loss: 1.8103 - acc: 0.2652 - val_loss: 1.4961 - val_acc: 0.3393\n",
      "Epoch 3/60\n",
      "132/132 [==============================] - 0s 212us/step - loss: 1.5802 - acc: 0.3561 - val_loss: 1.4678 - val_acc: 0.3929\n",
      "Epoch 4/60\n",
      "132/132 [==============================] - 0s 265us/step - loss: 1.6381 - acc: 0.3409 - val_loss: 1.4655 - val_acc: 0.3929\n",
      "Epoch 5/60\n",
      "132/132 [==============================] - 0s 235us/step - loss: 1.5768 - acc: 0.3106 - val_loss: 1.4635 - val_acc: 0.3929\n",
      "Epoch 6/60\n",
      "132/132 [==============================] - 0s 273us/step - loss: 1.4622 - acc: 0.3788 - val_loss: 1.4463 - val_acc: 0.3571\n",
      "Epoch 7/60\n",
      "132/132 [==============================] - 0s 220us/step - loss: 1.4566 - acc: 0.4167 - val_loss: 1.4179 - val_acc: 0.3571\n",
      "Epoch 8/60\n",
      "132/132 [==============================] - 0s 262us/step - loss: 1.3935 - acc: 0.4167 - val_loss: 1.4294 - val_acc: 0.4107\n",
      "Epoch 9/60\n",
      "132/132 [==============================] - 0s 239us/step - loss: 1.3574 - acc: 0.4545 - val_loss: 1.4401 - val_acc: 0.3393\n",
      "Epoch 10/60\n",
      "132/132 [==============================] - 0s 256us/step - loss: 1.3187 - acc: 0.4318 - val_loss: 1.4243 - val_acc: 0.3929\n",
      "Epoch 11/60\n",
      "132/132 [==============================] - 0s 235us/step - loss: 1.2574 - acc: 0.4697 - val_loss: 1.4214 - val_acc: 0.4107\n",
      "Epoch 12/60\n",
      "132/132 [==============================] - 0s 243us/step - loss: 1.1756 - acc: 0.4924 - val_loss: 1.4156 - val_acc: 0.4107\n",
      "Epoch 13/60\n",
      "132/132 [==============================] - 0s 307us/step - loss: 1.2472 - acc: 0.4848 - val_loss: 1.4079 - val_acc: 0.3750\n",
      "Epoch 14/60\n",
      "132/132 [==============================] - 0s 267us/step - loss: 1.0729 - acc: 0.6136 - val_loss: 1.3908 - val_acc: 0.3571\n",
      "Epoch 15/60\n",
      "132/132 [==============================] - 0s 222us/step - loss: 0.9845 - acc: 0.6288 - val_loss: 1.4108 - val_acc: 0.4107\n",
      "Epoch 16/60\n",
      "132/132 [==============================] - 0s 256us/step - loss: 1.0117 - acc: 0.5985 - val_loss: 1.3725 - val_acc: 0.4286\n",
      "Epoch 17/60\n",
      "132/132 [==============================] - 0s 249us/step - loss: 0.9624 - acc: 0.6439 - val_loss: 1.3496 - val_acc: 0.4107\n",
      "Epoch 18/60\n",
      "132/132 [==============================] - 0s 264us/step - loss: 0.9389 - acc: 0.5909 - val_loss: 1.3855 - val_acc: 0.3929\n",
      "Epoch 19/60\n",
      "132/132 [==============================] - 0s 245us/step - loss: 0.7715 - acc: 0.6894 - val_loss: 1.4953 - val_acc: 0.3571\n",
      "Epoch 20/60\n",
      "132/132 [==============================] - 0s 256us/step - loss: 0.7649 - acc: 0.6894 - val_loss: 1.4543 - val_acc: 0.3571\n",
      "Epoch 21/60\n",
      "132/132 [==============================] - 0s 277us/step - loss: 0.7056 - acc: 0.7500 - val_loss: 1.3922 - val_acc: 0.4643\n",
      "Epoch 22/60\n",
      "132/132 [==============================] - 0s 271us/step - loss: 0.8079 - acc: 0.7121 - val_loss: 1.4285 - val_acc: 0.4107\n",
      "Epoch 23/60\n",
      "132/132 [==============================] - 0s 273us/step - loss: 0.6541 - acc: 0.7576 - val_loss: 1.5717 - val_acc: 0.3750\n",
      "Epoch 24/60\n",
      "132/132 [==============================] - 0s 256us/step - loss: 0.6360 - acc: 0.7955 - val_loss: 1.4579 - val_acc: 0.4464\n",
      "Epoch 25/60\n",
      "132/132 [==============================] - 0s 234us/step - loss: 0.5882 - acc: 0.8182 - val_loss: 1.4322 - val_acc: 0.4286\n",
      "Epoch 26/60\n",
      "132/132 [==============================] - 0s 226us/step - loss: 0.6187 - acc: 0.7803 - val_loss: 1.3877 - val_acc: 0.5179\n",
      "Epoch 27/60\n",
      "132/132 [==============================] - 0s 226us/step - loss: 0.5679 - acc: 0.7879 - val_loss: 1.3942 - val_acc: 0.4107\n",
      "Epoch 28/60\n",
      "132/132 [==============================] - 0s 243us/step - loss: 0.4906 - acc: 0.8409 - val_loss: 1.2798 - val_acc: 0.5179\n",
      "Epoch 29/60\n",
      "132/132 [==============================] - 0s 240us/step - loss: 0.4993 - acc: 0.8409 - val_loss: 1.3039 - val_acc: 0.4821\n",
      "Epoch 30/60\n",
      "132/132 [==============================] - 0s 238us/step - loss: 0.4750 - acc: 0.8258 - val_loss: 1.3605 - val_acc: 0.5000\n",
      "Epoch 31/60\n",
      "132/132 [==============================] - 0s 242us/step - loss: 0.4587 - acc: 0.8409 - val_loss: 1.3100 - val_acc: 0.5179\n",
      "Epoch 32/60\n",
      "132/132 [==============================] - 0s 225us/step - loss: 0.3520 - acc: 0.8712 - val_loss: 1.3660 - val_acc: 0.5000\n",
      "Epoch 33/60\n",
      "132/132 [==============================] - 0s 255us/step - loss: 0.4068 - acc: 0.8939 - val_loss: 1.3528 - val_acc: 0.5714\n",
      "Epoch 34/60\n",
      "132/132 [==============================] - 0s 263us/step - loss: 0.3693 - acc: 0.8864 - val_loss: 1.4149 - val_acc: 0.5714\n",
      "Epoch 35/60\n",
      "132/132 [==============================] - 0s 271us/step - loss: 0.3653 - acc: 0.9015 - val_loss: 1.4948 - val_acc: 0.4821\n",
      "Epoch 36/60\n",
      "132/132 [==============================] - 0s 260us/step - loss: 0.2970 - acc: 0.9242 - val_loss: 1.4272 - val_acc: 0.4821\n",
      "Epoch 37/60\n",
      "132/132 [==============================] - 0s 249us/step - loss: 0.3474 - acc: 0.9091 - val_loss: 1.4136 - val_acc: 0.5714\n",
      "Epoch 38/60\n",
      "132/132 [==============================] - 0s 206us/step - loss: 0.2465 - acc: 0.9621 - val_loss: 1.4405 - val_acc: 0.5536\n",
      "Epoch 39/60\n",
      "132/132 [==============================] - 0s 217us/step - loss: 0.2736 - acc: 0.9470 - val_loss: 1.4626 - val_acc: 0.5179\n",
      "Epoch 40/60\n",
      "132/132 [==============================] - 0s 239us/step - loss: 0.2028 - acc: 0.9621 - val_loss: 1.4040 - val_acc: 0.5536\n",
      "Epoch 41/60\n",
      "132/132 [==============================] - 0s 236us/step - loss: 0.2777 - acc: 0.9470 - val_loss: 1.3694 - val_acc: 0.5714\n",
      "Epoch 42/60\n",
      "132/132 [==============================] - 0s 224us/step - loss: 0.1870 - acc: 0.9621 - val_loss: 1.3923 - val_acc: 0.5714\n",
      "Epoch 43/60\n",
      "132/132 [==============================] - 0s 203us/step - loss: 0.2382 - acc: 0.9394 - val_loss: 1.4659 - val_acc: 0.5000\n",
      "Epoch 44/60\n",
      "132/132 [==============================] - 0s 205us/step - loss: 0.1947 - acc: 0.9621 - val_loss: 1.5139 - val_acc: 0.5357\n",
      "Epoch 45/60\n",
      "132/132 [==============================] - 0s 224us/step - loss: 0.2261 - acc: 0.9394 - val_loss: 1.4812 - val_acc: 0.5714\n",
      "Epoch 46/60\n",
      "132/132 [==============================] - 0s 251us/step - loss: 0.2505 - acc: 0.9318 - val_loss: 1.4022 - val_acc: 0.6071\n",
      "Epoch 47/60\n",
      "132/132 [==============================] - 0s 296us/step - loss: 0.2272 - acc: 0.9470 - val_loss: 1.4858 - val_acc: 0.5179\n",
      "Epoch 48/60\n",
      "132/132 [==============================] - 0s 250us/step - loss: 0.2409 - acc: 0.9394 - val_loss: 1.4750 - val_acc: 0.5714\n",
      "Epoch 49/60\n",
      "132/132 [==============================] - 0s 245us/step - loss: 0.2020 - acc: 0.9470 - val_loss: 1.5371 - val_acc: 0.5893\n",
      "Epoch 50/60\n",
      "132/132 [==============================] - 0s 239us/step - loss: 0.1617 - acc: 0.9470 - val_loss: 1.4997 - val_acc: 0.5893\n",
      "Epoch 51/60\n",
      "132/132 [==============================] - 0s 254us/step - loss: 0.1895 - acc: 0.9545 - val_loss: 1.4830 - val_acc: 0.5357\n",
      "Epoch 52/60\n",
      "132/132 [==============================] - 0s 240us/step - loss: 0.1381 - acc: 0.9697 - val_loss: 1.5123 - val_acc: 0.5536\n",
      "Epoch 53/60\n",
      "132/132 [==============================] - 0s 261us/step - loss: 0.1037 - acc: 0.9924 - val_loss: 1.5833 - val_acc: 0.6071\n",
      "Epoch 54/60\n",
      "132/132 [==============================] - 0s 216us/step - loss: 0.1332 - acc: 0.9773 - val_loss: 1.6146 - val_acc: 0.5714\n",
      "Epoch 55/60\n",
      "132/132 [==============================] - 0s 240us/step - loss: 0.1090 - acc: 0.9773 - val_loss: 1.5948 - val_acc: 0.5714\n",
      "Epoch 56/60\n",
      "132/132 [==============================] - 0s 253us/step - loss: 0.0975 - acc: 0.9924 - val_loss: 1.5843 - val_acc: 0.5536\n",
      "Epoch 57/60\n",
      "132/132 [==============================] - 0s 237us/step - loss: 0.1117 - acc: 0.9773 - val_loss: 1.5888 - val_acc: 0.5536\n",
      "Epoch 58/60\n",
      "132/132 [==============================] - 0s 259us/step - loss: 0.1309 - acc: 0.9545 - val_loss: 1.6120 - val_acc: 0.5536\n",
      "Epoch 59/60\n",
      "132/132 [==============================] - 0s 242us/step - loss: 0.1024 - acc: 0.9848 - val_loss: 1.6205 - val_acc: 0.5893\n",
      "Epoch 60/60\n",
      "132/132 [==============================] - 0s 224us/step - loss: 0.1268 - acc: 0.9621 - val_loss: 1.6389 - val_acc: 0.5536\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 60, batch_size=32,shuffle=True,validation_data = (embedding_matrix_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5535714285714286"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "\n",
    "float(sum(pred==y_act))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132 samples, validate on 56 samples\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5972 - acc: 0.2500 - val_loss: 1.5324 - val_acc: 0.3214\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 866us/step - loss: 1.5509 - acc: 0.2955 - val_loss: 1.5120 - val_acc: 0.2857\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 841us/step - loss: 1.4876 - acc: 0.3106 - val_loss: 1.4637 - val_acc: 0.3393\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 811us/step - loss: 1.4314 - acc: 0.3485 - val_loss: 1.4184 - val_acc: 0.3750\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 837us/step - loss: 1.3583 - acc: 0.4394 - val_loss: 1.3508 - val_acc: 0.4464\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 855us/step - loss: 1.2147 - acc: 0.5985 - val_loss: 1.2677 - val_acc: 0.5179\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 783us/step - loss: 1.0747 - acc: 0.6212 - val_loss: 1.1847 - val_acc: 0.4643\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 834us/step - loss: 0.9370 - acc: 0.6667 - val_loss: 1.1240 - val_acc: 0.5536\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.8726 - acc: 0.6894 - val_loss: 1.0886 - val_acc: 0.4821\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8116 - acc: 0.6970 - val_loss: 1.1066 - val_acc: 0.4643\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.7373 - acc: 0.7197 - val_loss: 1.0200 - val_acc: 0.4821\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6138 - acc: 0.8030 - val_loss: 0.9936 - val_acc: 0.5536\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 962us/step - loss: 0.5620 - acc: 0.8106 - val_loss: 1.0535 - val_acc: 0.5357\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 849us/step - loss: 0.5265 - acc: 0.7879 - val_loss: 1.0547 - val_acc: 0.6607\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.4119 - acc: 0.8561 - val_loss: 1.1498 - val_acc: 0.5893\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 893us/step - loss: 0.4001 - acc: 0.8561 - val_loss: 1.1506 - val_acc: 0.6250\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 798us/step - loss: 0.4900 - acc: 0.8409 - val_loss: 1.1368 - val_acc: 0.6250\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 819us/step - loss: 0.4420 - acc: 0.8333 - val_loss: 1.1853 - val_acc: 0.6071\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 879us/step - loss: 0.3952 - acc: 0.8636 - val_loss: 1.0840 - val_acc: 0.6250\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 958us/step - loss: 0.3206 - acc: 0.8864 - val_loss: 1.1164 - val_acc: 0.6607\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2994 - acc: 0.9167 - val_loss: 0.9825 - val_acc: 0.6607\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3199 - acc: 0.8788 - val_loss: 1.1190 - val_acc: 0.6429\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2283 - acc: 0.9167 - val_loss: 1.3264 - val_acc: 0.5893\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 877us/step - loss: 0.2603 - acc: 0.8939 - val_loss: 1.3318 - val_acc: 0.5893\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 900us/step - loss: 0.1647 - acc: 0.9394 - val_loss: 1.3585 - val_acc: 0.6429\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 810us/step - loss: 0.1630 - acc: 0.9242 - val_loss: 1.5637 - val_acc: 0.6607\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 935us/step - loss: 0.1149 - acc: 0.9621 - val_loss: 1.7321 - val_acc: 0.6071\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1569 - acc: 0.9394 - val_loss: 1.5158 - val_acc: 0.6250\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2496 - acc: 0.8939 - val_loss: 1.7693 - val_acc: 0.6071\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1528 - acc: 0.9621 - val_loss: 1.6268 - val_acc: 0.5893\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 964us/step - loss: 0.1575 - acc: 0.9318 - val_loss: 2.0232 - val_acc: 0.5893\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 858us/step - loss: 0.3199 - acc: 0.8864 - val_loss: 1.4544 - val_acc: 0.5893\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 870us/step - loss: 0.5416 - acc: 0.8106 - val_loss: 1.3882 - val_acc: 0.6071\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 818us/step - loss: 0.4423 - acc: 0.8712 - val_loss: 1.5807 - val_acc: 0.5714\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 902us/step - loss: 0.3103 - acc: 0.9242 - val_loss: 1.2671 - val_acc: 0.6786\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 837us/step - loss: 0.1609 - acc: 0.9545 - val_loss: 1.1649 - val_acc: 0.6607\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 711us/step - loss: 0.1504 - acc: 0.9470 - val_loss: 1.1170 - val_acc: 0.6607\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 694us/step - loss: 0.1175 - acc: 0.9773 - val_loss: 1.1928 - val_acc: 0.6786\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 731us/step - loss: 0.0952 - acc: 0.9773 - val_loss: 1.3085 - val_acc: 0.6429\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 773us/step - loss: 0.0680 - acc: 0.9848 - val_loss: 1.4752 - val_acc: 0.6250\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 757us/step - loss: 0.0599 - acc: 0.9924 - val_loss: 1.6000 - val_acc: 0.6429\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.0488 - acc: 0.9924 - val_loss: 1.6855 - val_acc: 0.6429\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 906us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 1.7877 - val_acc: 0.6429\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 940us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.8731 - val_acc: 0.6607\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 906us/step - loss: 0.0464 - acc: 0.9848 - val_loss: 1.8360 - val_acc: 0.6250\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 916us/step - loss: 0.0380 - acc: 0.9848 - val_loss: 1.8460 - val_acc: 0.6607\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 797us/step - loss: 0.0550 - acc: 0.9848 - val_loss: 1.9265 - val_acc: 0.6250\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 733us/step - loss: 0.0321 - acc: 0.9924 - val_loss: 2.0957 - val_acc: 0.6250\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 742us/step - loss: 0.0475 - acc: 0.9848 - val_loss: 2.1925 - val_acc: 0.6250\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 735us/step - loss: 0.0883 - acc: 0.9697 - val_loss: 1.9541 - val_acc: 0.6429\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 50, batch_size=32,shuffle=True,validation_data = (embedding_matrix_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "\n",
    "float(sum(pred==y_act))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 40,709\n",
      "Trainable params: 40,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 1.6155 - acc: 0.2424 - val_loss: 1.5608 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 381us/step - loss: 1.5564 - acc: 0.3106 - val_loss: 1.5422 - val_acc: 0.3036\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 387us/step - loss: 1.5378 - acc: 0.2955 - val_loss: 1.5224 - val_acc: 0.2857\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 394us/step - loss: 1.4767 - acc: 0.3485 - val_loss: 1.4913 - val_acc: 0.4286\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 460us/step - loss: 1.4874 - acc: 0.3409 - val_loss: 1.4542 - val_acc: 0.4107\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 491us/step - loss: 1.4050 - acc: 0.4394 - val_loss: 1.4089 - val_acc: 0.4464\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 539us/step - loss: 1.3711 - acc: 0.3788 - val_loss: 1.3721 - val_acc: 0.4821\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 482us/step - loss: 1.2892 - acc: 0.5152 - val_loss: 1.3409 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 516us/step - loss: 1.2071 - acc: 0.5455 - val_loss: 1.3496 - val_acc: 0.4821\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 504us/step - loss: 1.1925 - acc: 0.5758 - val_loss: 1.3248 - val_acc: 0.4464\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 509us/step - loss: 1.0751 - acc: 0.6288 - val_loss: 1.1758 - val_acc: 0.4821\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 502us/step - loss: 1.0606 - acc: 0.5758 - val_loss: 1.2072 - val_acc: 0.4107\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 501us/step - loss: 1.0645 - acc: 0.5606 - val_loss: 1.1404 - val_acc: 0.4643\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 524us/step - loss: 0.9156 - acc: 0.6667 - val_loss: 1.2198 - val_acc: 0.4286\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 518us/step - loss: 0.8535 - acc: 0.6818 - val_loss: 1.1377 - val_acc: 0.5179\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 427us/step - loss: 0.8219 - acc: 0.7348 - val_loss: 1.1040 - val_acc: 0.5357\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 455us/step - loss: 0.7825 - acc: 0.7045 - val_loss: 1.0960 - val_acc: 0.5179\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 393us/step - loss: 0.6974 - acc: 0.7803 - val_loss: 1.0409 - val_acc: 0.5714\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 425us/step - loss: 0.6545 - acc: 0.7652 - val_loss: 1.0978 - val_acc: 0.5179\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 510us/step - loss: 0.6058 - acc: 0.7652 - val_loss: 1.0942 - val_acc: 0.5179\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 504us/step - loss: 0.5143 - acc: 0.8561 - val_loss: 1.0547 - val_acc: 0.5893\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 607us/step - loss: 0.4941 - acc: 0.8409 - val_loss: 1.0396 - val_acc: 0.5893\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 552us/step - loss: 0.5130 - acc: 0.8333 - val_loss: 0.9956 - val_acc: 0.6071\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 517us/step - loss: 0.4320 - acc: 0.8939 - val_loss: 1.0590 - val_acc: 0.6071\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 492us/step - loss: 0.3819 - acc: 0.9015 - val_loss: 1.0679 - val_acc: 0.6071\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 568us/step - loss: 0.3667 - acc: 0.8788 - val_loss: 1.0734 - val_acc: 0.5714\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 540us/step - loss: 0.4296 - acc: 0.8636 - val_loss: 0.9775 - val_acc: 0.6429\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 500us/step - loss: 0.3256 - acc: 0.8864 - val_loss: 1.1595 - val_acc: 0.6250\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 442us/step - loss: 0.3621 - acc: 0.8788 - val_loss: 0.9736 - val_acc: 0.6786\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 426us/step - loss: 0.3096 - acc: 0.8939 - val_loss: 1.0960 - val_acc: 0.6250\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 577us/step - loss: 0.2154 - acc: 0.9621 - val_loss: 1.2275 - val_acc: 0.6250\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 543us/step - loss: 0.2501 - acc: 0.9242 - val_loss: 1.1468 - val_acc: 0.6607\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 545us/step - loss: 0.2645 - acc: 0.9091 - val_loss: 1.1984 - val_acc: 0.6250\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 530us/step - loss: 0.2307 - acc: 0.9470 - val_loss: 1.1606 - val_acc: 0.6786\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 520us/step - loss: 0.1653 - acc: 0.9697 - val_loss: 1.0494 - val_acc: 0.6964\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 629us/step - loss: 0.1666 - acc: 0.9621 - val_loss: 1.1775 - val_acc: 0.6607\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 415us/step - loss: 0.1437 - acc: 0.9697 - val_loss: 1.2162 - val_acc: 0.6607\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 407us/step - loss: 0.1832 - acc: 0.9470 - val_loss: 1.2813 - val_acc: 0.6429\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 415us/step - loss: 0.2097 - acc: 0.9318 - val_loss: 1.1524 - val_acc: 0.6607\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 423us/step - loss: 0.1775 - acc: 0.9545 - val_loss: 1.3441 - val_acc: 0.6786\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 433us/step - loss: 0.1761 - acc: 0.9470 - val_loss: 1.2220 - val_acc: 0.6250\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 420us/step - loss: 0.1204 - acc: 0.9773 - val_loss: 1.3752 - val_acc: 0.6250\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 398us/step - loss: 0.1421 - acc: 0.9697 - val_loss: 1.4580 - val_acc: 0.6607\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 443us/step - loss: 0.1157 - acc: 0.9697 - val_loss: 1.3109 - val_acc: 0.6250\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 479us/step - loss: 0.1949 - acc: 0.9470 - val_loss: 1.2490 - val_acc: 0.6607\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 411us/step - loss: 0.1036 - acc: 0.9697 - val_loss: 1.3988 - val_acc: 0.6429\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 414us/step - loss: 0.0731 - acc: 0.9924 - val_loss: 1.3547 - val_acc: 0.6607\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 434us/step - loss: 0.0892 - acc: 0.9697 - val_loss: 1.3362 - val_acc: 0.6429\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 444us/step - loss: 0.0725 - acc: 0.9924 - val_loss: 1.3930 - val_acc: 0.6250\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 431us/step - loss: 0.0433 - acc: 0.9924 - val_loss: 1.4222 - val_acc: 0.6429\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 443us/step - loss: 0.0778 - acc: 0.9924 - val_loss: 1.4615 - val_acc: 0.6429\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 426us/step - loss: 0.0697 - acc: 0.9848 - val_loss: 1.4339 - val_acc: 0.6607\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 454us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 1.5104 - val_acc: 0.6250\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 435us/step - loss: 0.0621 - acc: 0.9773 - val_loss: 1.5981 - val_acc: 0.6607\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 406us/step - loss: 0.0543 - acc: 0.9848 - val_loss: 1.6349 - val_acc: 0.6250\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 416us/step - loss: 0.1022 - acc: 0.9621 - val_loss: 1.5916 - val_acc: 0.6429\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 439us/step - loss: 0.0706 - acc: 0.9697 - val_loss: 1.5919 - val_acc: 0.6786\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 426us/step - loss: 0.0881 - acc: 0.9848 - val_loss: 1.5755 - val_acc: 0.6607\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 484us/step - loss: 0.0639 - acc: 0.9773 - val_loss: 1.6467 - val_acc: 0.6429\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 453us/step - loss: 0.0613 - acc: 0.9924 - val_loss: 1.5781 - val_acc: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 485us/step - loss: 0.0525 - acc: 0.9773 - val_loss: 1.6206 - val_acc: 0.6964\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 446us/step - loss: 0.0453 - acc: 0.9848 - val_loss: 1.5532 - val_acc: 0.6607\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 448us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 1.4977 - val_acc: 0.6786\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 422us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.5041 - val_acc: 0.6607\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 446us/step - loss: 0.0228 - acc: 0.9924 - val_loss: 1.5304 - val_acc: 0.6607\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 389us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.5485 - val_acc: 0.6429\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 405us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 1.5455 - val_acc: 0.6607\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 412us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 1.4705 - val_acc: 0.6607\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 398us/step - loss: 0.0263 - acc: 0.9924 - val_loss: 1.6611 - val_acc: 0.6607\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 459us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.6534 - val_acc: 0.6607\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 470us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 1.6099 - val_acc: 0.6607\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 425us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.6482 - val_acc: 0.6607\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 440us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 1.6859 - val_acc: 0.6786\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 446us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.7107 - val_acc: 0.6786\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 391us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7146 - val_acc: 0.6786\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 418us/step - loss: 0.0242 - acc: 0.9924 - val_loss: 1.8262 - val_acc: 0.6786\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 510us/step - loss: 0.0195 - acc: 0.9924 - val_loss: 1.7544 - val_acc: 0.6250\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 670us/step - loss: 0.0347 - acc: 0.9924 - val_loss: 1.8748 - val_acc: 0.6786\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 472us/step - loss: 0.0639 - acc: 0.9773 - val_loss: 1.7395 - val_acc: 0.6607\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 405us/step - loss: 0.0507 - acc: 0.9848 - val_loss: 1.7254 - val_acc: 0.6607\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 424us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.9524 - val_acc: 0.6429\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 454us/step - loss: 0.0349 - acc: 0.9848 - val_loss: 1.6773 - val_acc: 0.6607\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 482us/step - loss: 0.0435 - acc: 0.9848 - val_loss: 1.5978 - val_acc: 0.6429\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 463us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.7008 - val_acc: 0.6786\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 412us/step - loss: 0.0346 - acc: 0.9924 - val_loss: 1.8709 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 409us/step - loss: 0.0528 - acc: 0.9773 - val_loss: 1.7901 - val_acc: 0.7143\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 454us/step - loss: 0.0585 - acc: 0.9773 - val_loss: 1.7203 - val_acc: 0.7143\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 450us/step - loss: 0.0568 - acc: 0.9773 - val_loss: 2.2003 - val_acc: 0.6250\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 454us/step - loss: 0.0370 - acc: 0.9924 - val_loss: 2.1442 - val_acc: 0.6071\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 496us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 1.7959 - val_acc: 0.6607\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 450us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6647 - val_acc: 0.6607\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 461us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.6306 - val_acc: 0.6786\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 455us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.6546 - val_acc: 0.6786\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 446us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.7161 - val_acc: 0.6964\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 451us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.7913 - val_acc: 0.6786\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 470us/step - loss: 0.0113 - acc: 0.9924 - val_loss: 1.8060 - val_acc: 0.6786\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 473us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.7842 - val_acc: 0.6786\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 437us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.7312 - val_acc: 0.6786\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 430us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.7213 - val_acc: 0.6964\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 407us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.7422 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(embedding_matrix_train,y_train,epochs = 100, batch_size=32,shuffle=True,validation_data = (embedding_matrix_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "\n",
    "float(sum(pred==y_act))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
